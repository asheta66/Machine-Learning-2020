{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "11_nltk_filter_stop_words.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asheta66/Machine-Learning-2020/blob/main/NLP%20Programming/chapter_05/11_nltk_filter_stop_words.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOcpI-Vz_v2D"
      },
      "source": [
        "import string\n",
        "import re\n",
        "import nltk\n",
        "nltk.download('all')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ8GhvdBEIsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f38d8b3b-e421-4c3f-f5f7-cc4b463b51a1"
      },
      "source": [
        "# load text\r\n",
        "filename = 'https://raw.githubusercontent.com/asheta66/Machine-Learning-2020/main/Datasets/NLP/metamorphosis_clean.txt'\r\n",
        "req = requests.get(filename)\r\n",
        "text=req.text\r\n",
        "# split into words\r\n",
        "tokens = word_tokenize(text)\r\n",
        "# convert to lower case\r\n",
        "tokens = [w.lower() for w in tokens]\r\n",
        "# prepare regex for char filtering\r\n",
        "re_punc = re.compile('[%s]' % re.escape(string.punctuation))\r\n",
        "# remove punctuation from each word\r\n",
        "stripped = [re_punc.sub('', w) for w in tokens]\r\n",
        "# remove remaining tokens that are not alphabetic\r\n",
        "words = [word for word in stripped if word.isalpha()]\r\n",
        "# filter out stop words\r\n",
        "stop_words = set(stopwords.words('english'))\r\n",
        "words = [w for w in words if not w in stop_words]\r\n",
        "print(words[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['one', 'morning', 'gregor', 'samsa', 'woke', 'troubled', 'dreams', 'found', 'transformed', 'bed', 'horrible', 'vermin', 'lay', 'armourlike', 'back', 'lifted', 'head', 'little', 'could', 'see', 'brown', 'belly', 'slightly', 'domed', 'divided', 'arches', 'stiff', 'sections', 'bedding', 'hardly', 'able', 'cover', 'seemed', 'ready', 'slide', 'moment', 'many', 'legs', 'pitifully', 'thin', 'compared', 'size', 'rest', 'waved', 'helplessly', 'looked', 'happened', 'thought', 'nt', 'dream', 'room', 'proper', 'human', 'room', 'although', 'little', 'small', 'lay', 'peacefully', 'four', 'familiar', 'walls', 'collection', 'textile', 'samples', 'lay', 'spread', 'table', 'samsa', 'travelling', 'salesman', 'hung', 'picture', 'recently', 'cut', 'illustrated', 'magazine', 'housed', 'nice', 'gilded', 'frame', 'showed', 'lady', 'fitted', 'fur', 'hat', 'fur', 'boa', 'sat', 'upright', 'raising', 'heavy', 'fur', 'muff', 'covered', 'whole', 'lower', 'arm', 'towards', 'viewer']\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}