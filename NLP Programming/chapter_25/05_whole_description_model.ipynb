{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": ["from keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.utils import to_categorical\n\n# load doc into memory\ndef load_doc(filename):\n\t# open the file as read only\n\tfile = open(filename, 'r')\n\t# read all text\n\ttext = file.read()\n\t# close the file\n\tfile.close()\n\treturn text\n\n# load clean descriptions into memory\ndef load_clean_descriptions(filename):\n\tdoc = load_doc(filename)\n\tdescriptions = dict()\n\tfor line in doc.split('\\n'):\n\t\t# split line by white space\n\t\ttokens = line.split()\n\t\t# split id from description\n\t\timage_id, image_desc = tokens[0], tokens[1:]\n\t\t# store\n\t\tdescriptions[image_id] = ' '.join(image_desc)\n\treturn descriptions\n\ndescriptions = load_clean_descriptions('descriptions.txt')\nprint('Loaded %d' % (len(descriptions)))\n# extract all text\ndesc_text = list(descriptions.values())\n# prepare tokenizer\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(desc_text)\nvocab_size = len(tokenizer.word_index) + 1\nprint('Vocabulary Size: %d' % vocab_size)\n# integer encode descriptions\nsequences = tokenizer.texts_to_sequences(desc_text)\n# pad all sequences to a fixed length\nmax_length = max(len(s) for s in sequences)\nprint('Description Length: %d' % max_length)\npadded = pad_sequences(sequences, maxlen=max_length, padding='post')\n# one hot encode\ny = to_categorical(padded, num_classes=vocab_size)\ny = y.reshape((len(descriptions), max_length, vocab_size))\nprint(y.shape)"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}